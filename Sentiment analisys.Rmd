---
title: "Test"
author: "Andreas Methling"
date: "26/11/2021"
output: pdf_document
---

```{r, message=FALSE}
library(tidyverse)
library(lubridate)
library(magrittr)
library(FactoMineR)
library(factoextra)
library(uwot)
library(GGally)
library(rsample)
library(ggridges)
library(xgboost)
library(recipes)
library(parsnip)
library(glmnet)
library(tidymodels)
library(skimr)
library(VIM)
library(visdat)
library(ggmap)
library(ranger)
library(vip)
library(SnowballC)
library(tokenizers)
library(formatR)

```


# Data

```{r}
library(readr)

data_start <- read_csv("C:/Users/Simon ik mig/Downloads/lyrics-data.csv.zip") #Simon
artists_data <- read_csv("C:/Users/Simon ik mig/Downloads/artists-data (1).csv")# Simon 

artists_data %>%
  count(Genre)

#data_start <- read_csv("C:/Users/Mikkel/Desktop/UNI/SDS/M3/lyrics-data.csv") Mikkel 
#artists_data <- read_csv("C:/Users/Mikkel/Desktop/UNI/SDS/M3/artists-data.csv") Mikkel

```

**Artist data**
```{r}
artists = artists_data %>% 
  group_by(Artist) %>% 
  count(Genre) %>% 
  pivot_wider(names_from = Genre, values_from = n) %>% 
  replace_na(list(Pop = 0, "Hip Hop" = 0, Rock = 0, "Funk Carioca" = 0, "Sertanejo" = 0, Samba = 0 )) %>% 
  ungroup() %>% 
  left_join(artists_data, by = c("Artist")) %>% 
  select(-c(Genre, Genres, Popularity, Songs)) %>% 
  distinct()
```

**Data Rock or Pop**
```{r}
data_genre = data_start %>% 
  filter(Idiom == "ENGLISH") %>% 
  rename("Link" = "ALink") %>% 
  inner_join(artists, by = c("Link")) %>% 
  distinct() %>%
  mutate(name = paste(Artist, SName))%>%
  rename(text=Lyric) %>%
  filter(Pop==1 | Rock==1) %>%
  select(name, text, Pop, Rock) %>%
  distinct(name, .keep_all = T)



data_pop_rock=data_genre %>%
  mutate(genre = ifelse(Pop==1 & Rock == 1, "pop/rock", ifelse(Rock==1 & Pop==0, "Rock", ifelse(Rock == 0 & Pop == 1, "Pop", 0)))) %>%
  select(-c(Pop, Rock))

data_pop_rock_labels= data_pop_rock %>%
  select(name, genre)
```




**Data Rock and Pop**

```{r}
data = data_start %>% 
  filter(Idiom == "ENGLISH") %>% 
  rename("Link" = "ALink") %>% 
  inner_join(artists, by = c("Link")) %>% 
  distinct() %>%
  mutate(name = paste(Artist, SName))%>%
  rename(text=Lyric) %>%
  filter(Rock==1 & Pop==1) %>%
  select(name, text)%>%
  distinct(name, .keep_all = T)
```




# Preprocessing / EDA

First we tokenize the data. 
```{r}
library(tidytext)
text_genre_tidy = data_pop_rock %>% unnest_tokens(word, text, token = "words")

head(text_genre_tidy)
```

We remove short words and stopwords.
```{r}
text_genre_tidy %<>%
  filter(str_length(word) > 2 ) %>% 
  group_by(word) %>%
  ungroup() %>%
  anti_join(stop_words, by = 'word') 
```

We use the hunspell package, which seems to produce the best stemming for our data. Reducing a word to its “root” word. 
```{r}
library(hunspell)
text_genre_tidy %>%
  mutate(stem = hunspell_stem(word)) %>%
  unnest(stem) %>%
  count(stem, sort = TRUE)

text_genre_tidy %<>% 
  mutate(stem = hunspell_stem(word)) %>%
  unnest(stem) %>%
  select(-word) %>%
  rename(word = stem)

```

We weight the data using tf-idf (Term-frequency Inverse document frequency). 
```{r}
# TFIDF weights
text_tf_idf= text_genre_tidy %>%
group_by(name) %>%
  count(word, sort = TRUE) %>%
  ungroup() %>% 
  bind_tf_idf(word, name, n) %>%
  arrange(desc(tf_idf))


text_genre_tf_idf = text_tf_idf %>%
  left_join(data_pop_rock_labels)




```

We show the 25 most common words. 
```{r}
# TFIDF topwords
text_genre_tidy_rock= text_genre_tf_idf %>%
  filter(genre == "Rock")%>%
count(word, wt = tf_idf, sort = TRUE) %>% #remove
head(25)


text_genre_tidy_rock_pop= text_genre_tf_idf %>%
  filter(genre == "pop/rock")%>%
count(word, wt = tf_idf, sort = TRUE) %>% #remove
head(25)

text_genre_tidy_pop= text_genre_tf_idf %>%
  filter(genre == "Pop")%>%
count(word, wt = tf_idf, sort = TRUE) %>% #remove
head(25)

```

```{r}
labels_words <- text_genre_tf_idf %>%
group_by(genre) %>%
count(word, wt = tf_idf, sort = TRUE, name = "tf_idf") %>%
dplyr::slice(1:20) %>% #slice
ungroup()

```

```{r}
labels_words %>%
mutate(word = reorder_within(word, by = tf_idf, within = genre)) %>% #Pop & Rock
ggplot(aes(x = word, y = tf_idf, fill = genre)) +
geom_col(show.legend = FALSE) +
labs(x = NULL, y = "tf-idf") +
facet_wrap(~genre, ncol = 2, scales = "free") +
coord_flip() +
scale_x_reordered() +
theme(axis.text.y = element_text(size = 6))

```

##Rock wordcloud

EDA within the Pop and Rock genres. 
```{r}
text_tidy_rock = text_genre_tidy %>%
  filter(genre == "Rock")
```

```{r}
library(wordcloud)
```

```{r}
text_tidy_rock %>%
count(word) %>%
with(wordcloud(word, n,
max.words = 50,
color = "blue"))

```

##Pop wordcloud

EDA within the Pop and Rock genres. 
```{r}
text_tidy_Pop = text_genre_tidy %>%
filter(genre == "Pop")

```

```{r}
text_tidy_Pop %>%
count(word) %>%
with(wordcloud(word, n,
max.words = 50,
color = "blue"))

```

##Pop/Rock wordcloud
```{r}
text_tidy_Pop_Rock = text_genre_tidy %>%
filter(genre == "pop/rock")

```

```{r}
text_tidy_Pop_Rock %>%
count(word) %>%
with(wordcloud(word, n,
max.words = 50,
color = "blue"))

```


#Sentiment Analysis

## Rock_Pop

We do a sentiment analysis based on the Pop genre.
```{r}
library(textdata)

text_tidy_Pop_Rock_index= text_tidy_Pop_Rock %>%
mutate(index= 1:n())

```

We use the lexicons “bing” and “afinn” to get a measure for positivity and negativity for each word.
We use inner_join to only get the words we use from the lexicon.
```{r}
#Bing
sentiment_bing <- text_tidy_Pop_Rock_index %>%
inner_join(get_sentiments("bing")) %>%
count(word, index = index %/% 100, sentiment) %>%
mutate(lexicon = 'Bing')

```

```{r}
# Afinn
sentiment_afinn <- text_tidy_Pop_Rock_index %>%
inner_join(get_sentiments("afinn")) %>%
group_by(index = index %/% 100) %>%
summarise(sentiment = sum(value, na.rm = TRUE)) %>%
mutate(lexicon = 'AFINN')

```

We join the measures from both lexicons. 
```{r}
# Lets join them all together for plotting
sentiment_all <- sentiment_afinn %>%
bind_rows(sentiment_bing %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment = positive - negative) %>%
select(index, sentiment, lexicon))

```

We create a plot for the distribution between negative and positive words within the data genre.
```{r}
sentiment_all %>%
ggplot(aes(x = index, y = sentiment, fill = lexicon)) +
geom_col(show.legend = FALSE) +
facet_wrap(~ lexicon) +
labs(title = "Sentiment Analysis: “Pop",
subtitle = 'Using the Bing, AFINN lexicon')

```

### Senteminet wordcloud

We can now create a wordcloud looking at the positive and negative words in the Pop genre.
```{r}
text_tidy_Pop_Rock %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
filter(sentiment %in% c("positive", "negative")) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
as.data.frame() %>%
remove_rownames() %>%
column_to_rownames("word") %>%
comparison.cloud(colors = c("darkgreen", "red"),
max.words = 100,
title.size = 1.5)

```



## pop

We do a sentiment analysis based on the Pop genre.
```{r}
library(textdata)

text_tidy_Pop_index= text_tidy_Pop %>%
mutate(index= 1:n())

```

We use the lexicons “bing” and “afinn” to get a measure for positivity and negativity for each word.
We use inner_join to only get the words we use from the lexicon.
```{r}
#Bing
sentiment_bing_pop <- text_tidy_Pop_index %>%
inner_join(get_sentiments("bing")) %>%
count(word, index = index %/% 100, sentiment) %>%
mutate(lexicon = 'Bing')

```

```{r}
# Afinn
sentiment_afinn_pop <- text_tidy_Pop_index %>%
inner_join(get_sentiments("afinn")) %>%
group_by(index = index %/% 100) %>%
summarise(sentiment = sum(value, na.rm = TRUE)) %>%
mutate(lexicon = 'AFINN')

```

We join the measures from both lexicons. 
```{r}
# Lets join them all together for plotting
sentiment_all_pop <- sentiment_afinn_pop %>%
bind_rows(sentiment_bing_pop %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment = positive - negative) %>%
select(index, sentiment, lexicon))

```

We create a plot for the distribution between negative and positive words within the data genre.
```{r}
sentiment_all_pop %>%
ggplot(aes(x = index, y = sentiment, fill = lexicon)) +
geom_col(show.legend = FALSE) +
facet_wrap(~ lexicon) +
labs(title = "Sentiment Analysis: “Pop",
subtitle = 'Using the Bing, AFINN lexicon')

```

### Senteminet wordcloud

We can now create a wordcloud looking at the positive and negative words in the Pop genre.
```{r}
text_tidy_Pop %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
filter(sentiment %in% c("positive", "negative")) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
as.data.frame() %>%
remove_rownames() %>%
column_to_rownames("word") %>%
comparison.cloud(colors = c("darkgreen", "red"),
max.words = 100,
title.size = 1.5)

```



## Rock

We do a sentiment analysis based on the Pop genre.
```{r}
library(textdata)

text_tidy_Rock_index= text_tidy_rock %>%
mutate(index= 1:n())

```

We use the lexicons “bing” and “afinn” to get a measure for positivity and negativity for each word.
We use inner_join to only get the words we use from the lexicon.
```{r}
#Bing
sentiment_bing_rock <- text_tidy_Rock_index %>%
inner_join(get_sentiments("bing")) %>%
count(word, index = index %/% 100, sentiment) %>%
mutate(lexicon = 'Bing')

```

```{r}
# Afinn
sentiment_afinn_rock <- text_tidy_Rock_index %>%
inner_join(get_sentiments("afinn")) %>%
group_by(index = index %/% 100) %>%
summarise(sentiment = sum(value, na.rm = TRUE)) %>%
mutate(lexicon = 'AFINN')

```

We join the measures from both lexicons. 
```{r}
# Lets join them all together for plotting
sentiment_all_rock <- sentiment_afinn_rock %>%
bind_rows(sentiment_bing_rock %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
mutate(sentiment = positive - negative) %>%
select(index, sentiment, lexicon))

```

We create a plot for the distribution between negative and positive words within the data genre.
```{r}
sentiment_all_rock %>%
ggplot(aes(x = index, y = sentiment, fill = lexicon)) +
geom_col(show.legend = FALSE) +
facet_wrap(~ lexicon) +
labs(title = "Sentiment Analysis: “Rock",
subtitle = 'Using the Bing, AFINN lexicon')

```

### Senteminet wordcloud

We can now create a wordcloud looking at the positive and negative words in the Pop genre.
```{r}
text_tidy_rock %>%
inner_join(get_sentiments("bing")) %>%
count(word, sentiment, sort = TRUE) %>%
filter(sentiment %in% c("positive", "negative")) %>%
pivot_wider(names_from = sentiment, values_from = n, values_fill = 0) %>%
as.data.frame() %>%
remove_rownames() %>%
column_to_rownames("word") %>%
comparison.cloud(colors = c("darkgreen", "red"),
max.words = 100,
title.size = 1.5)

```

# Bands analysis 


We dont need the genre any more so we remove

```{r}
data_band = data_start %>% 
  filter(Idiom == "ENGLISH") %>% 
  rename("Link" = "ALink") %>% 
  inner_join(artists, by = c("Link")) %>% 
  distinct() %>%
  rename(text=Lyric) %>%
  filter(Pop==1 | Rock==1) %>%
  select(Artist, text)
```

We want to see the most active artists

```{r}
data_band %>%
  count(Artist, sort = T)
```

We pick the top 3 artists (in our opinion) Green day, Bon Jovi and Red Hot Chili Peppers!


```{r}
best_artists= data_band %>%
  filter(Artist %in% c("Green Day",  "Bon Jovi" , "Red Hot Chili Peppers" ))
  
```

First we tokenize the data. 
```{r}
library(tidytext)
text_band_tidy = best_artists %>% unnest_tokens(word, text, token = "words")

head(text_band_tidy)
```

We remove short words and stopwords.
```{r}
text_band_tidy %<>%
  filter(str_length(word) > 2 ) %>% 
  group_by(word) %>%
  ungroup() %>%
  anti_join(stop_words, by = 'word') 
```

We use the hunspell package, which seems to produce the best stemming for our data. Reducing a word to its “root” word. 
```{r}
library(hunspell)
text_band_tidy %>%
  mutate(stem = hunspell_stem(word)) %>%
  unnest(stem) %>%
  count(stem, sort = TRUE)

text_band_tidy %<>% 
  mutate(stem = hunspell_stem(word)) %>%
  unnest(stem) %>%
  select(-word) %>%
  rename(word = stem) 

```

We weight the data using tf-idf (Term-frequency Inverse document frequency). 
```{r}
# TFIDF weights
text_band_tf_idf= text_band_tidy %>%
group_by(Artist) %>%
  count(word, sort = TRUE) %>%
  ungroup() %>% 
  bind_tf_idf(word, Artist, n) %>%
  arrange(desc(tf_idf))
```

```{r}
labels_words <- text_band_tf_idf %>%
  group_by(Artist) %>%
  count(word, wt = tf_idf, sort = TRUE, name = "tf_idf") %>%
  dplyr::slice(1:12) %>% 
  ungroup() 

labels_words %>%
  mutate(word = reorder_within(word, by = tf_idf, within = Artist)) %>%
  ggplot(aes(x = word, y = tf_idf, fill = Artist)) +
  geom_col(show.legend = FALSE) +
  labs(x = NULL, y = "tf-idf") +
  facet_wrap(~Artist, ncol = 2, scales = "free") +
  coord_flip() +
  scale_x_reordered() +
  theme(axis.text.y = element_text(size = 6))
```

Hvis vi kan fjerne "intro" osv. 


## Noget andet 

```{r}
# Greenday

sentiment_green_day= text_band_tidy %>%
  filter(Artist == "Green Day") %>%
  inner_join(get_sentiments("bing")) %>% # pull out only sentiment words
  count(sentiment) %>% # count the # of positive & negative words
  spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
  mutate(sentiment = positive - negative) # # of positive words - # of negative owrds

# Bon Jovi

sentiment_Bon_Jovi= text_band_tidy %>%
  filter(Artist == "Bon Jovi") %>%
  inner_join(get_sentiments("bing")) %>% # pull out only sentiment words
  count(sentiment) %>% # count the # of positive & negative words
  spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
  mutate(sentiment = positive - negative) # # of positive words - # of negative owrds


# Red Hot Chilie Pepper

sentiment_RHCP= text_band_tidy %>%
  filter(Artist == "Red Hot Chili Peppers") %>%
  inner_join(get_sentiments("bing")) %>% # pull out only sentiment words
  count(sentiment) %>% # count the # of positive & negative words
  spread(sentiment, n, fill = 0) %>% # made data wide rather than narrow
  mutate(sentiment = positive - negative) # # of positive words - # of negative owrds

```
For at vi kan se sentiment over hver sang kan vi tilføje sang navne igen 

```{r}
data_song_name = data_start %>% 
  filter(Idiom == "ENGLISH") %>% 
  rename("Link" = "ALink") %>% 
  inner_join(artists, by = c("Link")) %>% 
  distinct() %>%
  filter(Artist %in% c("Bon Jovi", "Green Day", "Red Hot Chili Peppers")) %>%
  rename(text=Lyric) %>%
  filter(Pop==1 | Rock==1) %>%
  select(SName, text)
```



```{r}
library(tidytext)
text_song_tidy = data_song_name %>% unnest_tokens(word, text, token = "words")

head(text_song_tidy)
```

We remove short words and stopwords.
```{r}
text_song_tidy %<>%
  filter(str_length(word) > 2 ) %>% 
  group_by(word) %>%
  ungroup() %>%
  anti_join(stop_words, by = 'word') 
```

We use the hunspell package, which seems to produce the best stemming for our data. Reducing a word to its “root” word. 
```{r}
library(hunspell)
text_song_tidy %>%
  mutate(stem = hunspell_stem(word)) %>%
  unnest(stem) %>%
  count(stem, sort = TRUE)

text_song_tidy %<>% 
  mutate(stem = hunspell_stem(word)) %>%
  unnest(stem) %>%
  select(-word) %>%
  rename(word = stem) 

```
Igen fjern ord der ik gir meningn




```{r}
# TFIDF weights
text_song_tf_idf= text_song_tidy %>%
group_by(SName) %>%
  count(word, sort = TRUE) %>%
  ungroup() %>% 
  bind_tf_idf(word, SName, n) %>%
  arrange(desc(tf_idf))


# We can now add the band name 

data_song_artist = data_start %>% 
  filter(Idiom == "ENGLISH") %>% 
  rename("Link" = "ALink") %>% 
  inner_join(artists, by = c("Link")) %>% 
  distinct() %>%
  filter(Artist %in% c("Bon Jovi", "Green Day", "Red Hot Chili Peppers")) %>%
  rename(text=Lyric) %>%
  filter(Pop==1 | Rock==1) %>%
  select(Artist,SName)


text_song_tf_idf %<>%
  inner_join(data_song_artist, by= c("SName"))

# For Green Day

green_day_songs=text_song_tf_idf %>%
  filter(Artist == "Green Day") %>%
  arrange(desc(tf_idf))%>% 
  inner_join(get_sentiments("bing"))%>%
  mutate(sentiment= ifelse(sentiment == "negative", -1, 1)) %>%
  group_by(SName) %>%
  summarise(sum= sum(sentiment)) %>%
  mutate(sentiment_song= ifelse(sum > 0, "positive", ifelse(sum == 0, "neutral", "negative")))%>%
  count(sentiment_song)

# For RHCP

RHCP_songs=text_song_tf_idf %>%
  filter(Artist == "Red Hot Chili Peppers") %>%
  arrange(desc(tf_idf))%>% 
  inner_join(get_sentiments("bing"))%>%
  mutate(sentiment= ifelse(sentiment == "negative", -1, 1)) %>%
  group_by(SName) %>%
  summarise(sum= sum(sentiment)) %>%
  mutate(sentiment_song= ifelse(sum > 0, "positive", ifelse(sum == 0, "neutral", "negative")))%>%
  count(sentiment_song)

# Bon Jovi

Bon_Jovi_songs=text_song_tf_idf %>%
  filter(Artist == "Bon Jovi") %>%
  arrange(desc(tf_idf))%>% 
  inner_join(get_sentiments("bing"))%>%
  mutate(sentiment= ifelse(sentiment == "negative", -1, 1)) %>%
  group_by(SName) %>%
  summarise(sum= sum(sentiment)) %>%
  mutate(sentiment_song= ifelse(sum > 0, "positive", ifelse(sum == 0, "neutral", "negative")))%>%
  count(sentiment_song)


# For all 

all_songs=text_song_tf_idf %>%
  arrange(desc(tf_idf))%>% 
  inner_join(get_sentiments("bing"))%>%
  mutate(sentiment= ifelse(sentiment == "negative", -1, 1)) %>%
  group_by(SName) %>%
  summarise(sum= sum(sentiment)) %>%
  mutate(sentiment_song= ifelse(sum > 0, "positive", ifelse(sum == 0, "neutral", "negative")))%>%
  inner_join(data_song_artist, by= c("SName"))

# plot of sentiment by president
ggplot(all_songs, aes(x = Artist, y = sum, color = Artist)) + 
  geom_boxplot() # draw a boxplot for each president

```

## Sentiment over time

```{r}
data_releaseyear <- read_csv("data.csv") # ligger på Github
glimpse(data_releaseyear)
```


```{r}
release_year_bon_jovi= data_releaseyear %>% 
  filter(artists == "['Bon Jovi']") %>%
  select(name, year)

release_year_RHCP= data_releaseyear %>% 
  filter(artists == "['Red Hot Chili Peppers']") %>%
  select(name, year)

release_year_Green_Day= data_releaseyear %>% 
  filter(artists == "['Green Day']") %>%
  select(name, year)
```


We will innerjoin with the datasets above


```{r}
#Bon Jovi

Bon_Jovi_songs=text_song_tf_idf %>%
  filter(Artist == "Bon Jovi") %>%
  arrange(desc(tf_idf))%>% 
  inner_join(get_sentiments("bing"))%>%
  mutate(sentiment= ifelse(sentiment == "negative", -1, 1)) %>%
  group_by(SName) %>%
  summarise(sum= sum(sentiment)) %>%
  mutate(sentiment_song= ifelse(sum > 0, "positive", ifelse(sum == 0, "neutral", "negative"))) %>%
  inner_join(release_year_bon_jovi, by= c("SName" = "name")) %>%
  distinct(SName, .keep_all = T)


#RHCP
RHCP_songs=text_song_tf_idf %>%
  filter(Artist == "Red Hot Chili Peppers") %>%
  arrange(desc(tf_idf))%>% 
  inner_join(get_sentiments("bing"))%>%
  mutate(sentiment= ifelse(sentiment == "negative", -1, 1)) %>%
  group_by(SName) %>%
  summarise(sum= sum(sentiment)) %>%
  mutate(sentiment_song= ifelse(sum > 0, "positive", ifelse(sum == 0, "neutral", "negative"))) %>%
  inner_join(release_year_RHCP, by= c("SName" = "name")) %>%
  distinct(SName, .keep_all = T)

## Green Day

Green_day_songs=text_song_tf_idf %>%
  filter(Artist == "Green Day") %>%
  arrange(desc(tf_idf))%>% 
  inner_join(get_sentiments("bing"))%>%
  mutate(sentiment= ifelse(sentiment == "negative", -1, 1)) %>%
  group_by(SName) %>%
  summarise(sum= sum(sentiment)) %>%
  mutate(sentiment_song= ifelse(sum > 0, "positive", ifelse(sum == 0, "neutral", "negative"))) %>%
  inner_join(release_year_Green_Day, by= c("SName" = "name")) %>%
  distinct(SName, .keep_all = T)

```
Development over time 
```{r}

## Bon Jovi 
ggplot(Bon_Jovi_songs, aes(x = as.numeric(year), y = sum)) + 
  geom_point(aes(color = sentiment_song))+ # add points to our plot, color-coded by president
  geom_smooth(method = "auto") # pick a method & fit a model


## RHCP

ggplot(RHCP_songs, aes(x = as.numeric(year), y = sum)) + 
  geom_point(aes(color = sentiment_song))+ # add points to our plot, color-coded by president
  geom_smooth(method = "auto") # pick a method & fit a model


## Green Day

ggplot(Green_day_songs, aes(x = as.numeric(year), y = sum)) + 
  geom_point(aes(color = sentiment_song))+ # add points to our plot, color-coded by president
  geom_smooth(method = "auto") # pick a method & fit a model

```

Noget med Saddness og fear eftersom de alle er meget negative 

# Saddness og fear

```{r}
#NRC
sentiment_bing <- text_tidy_Pop_Rock_index %>%
inner_join(get_sentiments("nrc")) %>%
count(word, index = index %/% 100, sentiment) %>%
mutate(lexicon = 'Bing')


#Bon Jovi

Bon_Jovi_songs_joy_sadness=text_song_tf_idf %>%
  filter(Artist == "Bon Jovi") %>%
  arrange(desc(tf_idf))%>% 
  inner_join(get_sentiments("nrc"))%>%
  filter(sentiment %in% c("sadness", "joy")) %>%
  mutate(sentiment= ifelse(sentiment == "sadness", -1, 1)) %>%
  group_by(SName) %>%
  summarise(sum= sum(sentiment)) %>%
  mutate(sentiment_song= ifelse(sum > 0, "joy", ifelse(sum == 0, "neutral", "sadness"))) %>%
  inner_join(release_year_bon_jovi, by= c("SName" = "name")) %>%
  distinct(SName, .keep_all = T)

## Green Day

Green_Day_songs_joy_sadness=text_song_tf_idf %>%
  filter(Artist == "Green Day") %>%
  arrange(desc(tf_idf))%>% 
  inner_join(get_sentiments("nrc"))%>%
  filter(sentiment %in% c("sadness", "joy")) %>%
  mutate(sentiment= ifelse(sentiment == "sadness", -1, 1)) %>%
  group_by(SName) %>%
  summarise(sum= sum(sentiment)) %>%
  mutate(sentiment_song= ifelse(sum > 0, "joy", ifelse(sum == 0, "neutral", "sadness"))) %>%
  inner_join(release_year_Green_Day, by= c("SName" = "name")) %>%
  distinct(SName, .keep_all = T)

## RHCP

RHCP_songs_joy_sadness=text_song_tf_idf %>%
  filter(Artist == "Red Hot Chili Peppers") %>%
  arrange(desc(tf_idf))%>% 
  inner_join(get_sentiments("nrc"))%>%
  filter(sentiment %in% c("sadness", "joy")) %>%
  mutate(sentiment= ifelse(sentiment == "sadness", -1, 1)) %>%
  group_by(SName) %>%
  summarise(sum= sum(sentiment)) %>%
  mutate(sentiment_song= ifelse(sum > 0, "joy", ifelse(sum == 0, "neutral", "sadness"))) %>%
  inner_join(release_year_RHCP, by= c("SName" = "name")) %>%
  distinct(SName, .keep_all = T)


```
```{r}

## Bon Jovi 
ggplot(Bon_Jovi_songs_joy_sadness, aes(x = as.numeric(year), y = sum)) + 
  geom_point(aes(color = sentiment_song))+ # add points to our plot, color-coded by president
  geom_smooth(method = "auto") # pick a method & fit a model


## RHCP

ggplot(RHCP_songs_joy_sadness, aes(x = as.numeric(year), y = sum)) + 
  geom_point(aes(color = sentiment_song))+ # add points to our plot, color-coded by president
  geom_smooth(method = "auto") # pick a method & fit a model


## Green Day

ggplot(Green_Day_songs_joy_sadness, aes(x = as.numeric(year), y = sum)) + 
  geom_point(aes(color = sentiment_song))+ # add points to our plot, color-coded by president
  geom_smooth(method = "auto") # pick a method & fit a model

```




# Machine learning model


## Making labels

```{r}
text_tidy = data %>% unnest_tokens(word, text, token = "words")
head(text_tidy)
```

```{r}
text_tidy %<>%
  filter(str_length(word) > 2 ) %>% 
  group_by(word) %>%
  ungroup() %>%
  anti_join(stop_words, by = 'word') 
```

We use stemming 
```{r}
text_tidy %<>% 
  mutate(stem = hunspell_stem(word)) %>%
  unnest(stem) %>%
   select(-word) %>%
  rename(word = stem)
```

```{r}
top_10000_words=text_tidy %>%
  count(word,sort = T) %>%
  head(10000) %>%
  select(word)
data_top_10000=top_10000_words %>%
  left_join(text_tidy, by= c("word")) 
```

# Bing
```{r}
sentiment_bing= data_top_10000 %>%
  inner_join(get_sentiments("bing")) %>%
  mutate(sentiment= ifelse(sentiment == "positive", 1,0)) 
sentiment_bing %<>%
  group_by(name) %>%
  summarise(mean= mean(sentiment))%>%
  mutate(label= ifelse(mean>=0.5, 1,0))
```

# Afinn

```{r}
sentiment_afinn= data_top_10000 %>%
  inner_join(get_sentiments("afinn")) 
sentiment_afinn %<>%
  group_by(name) %>%
  summarise(mean= mean(value))%>%
  mutate(label= ifelse(mean>=0, 1,0))
```

# Data

```{r}
data_bing= sentiment_bing %>%
  inner_join(data)%>%
  select(text, label, name)
  
data_afinn= sentiment_afinn %>%
  inner_join(data)%>%
  select(text, label, name)
```


We now want to create a multiclass supervised machinelearning model to predict the sentiment of a song based on its lyrics.


First we look for missing values. 
```{r}
library(visdat)
vis_dat(data_bing)
```

We remove NA's and look at the distribution between the two classes.
```{r}
data_bing %<>%
  drop_na() %>%
  rename(y = label) %>%
  select(-name)
data_bing$y <- as.factor(data_bing$y)
data_bing %>% 
  count(y) %>% 
  ggplot(aes(x = y, y = n)) + 
  geom_col()
```
We can see that negative sentiment is much more represented than positive sentiment, so we have to do some down or upsampling. 

We will create three different receipes: one using embedding, one using tf-idf and one using Hash.

So we load the embeddings using the "textdata" package.

```{r}
library(textdata)
glove6b <- embedding_glove6b(dimensions = 100)
```



We create a training and test dataset using strata=y to get the same ratio between the classes in both the training and test dataset.  

```{r}
library(rsample)
set.seed(19)
tidy_split <- initial_split(data_bing, strata = y)
train_data <- training(tidy_split)
test_data <- testing(tidy_split)
```
We use downsampling only on the training data to better fit the model 

```{r}
train_data <- recipe(y~., data = train_data) %>%
  themis::step_downsample(y) %>% 
  prep() %>% 
  juice()
train_data %>%
  count(y)
```
And can now see that the classes are evenly distributed. 


We create the three recipies we want to use. 
```{r}
library(textrecipes)
tf_idf_rec <- recipe(y~., data = train_data) %>% 
  step_tokenize(text) %>% 
  step_stem(text) %>% 
  step_stopwords(text) %>% 
  step_tokenfilter(text, max_tokens = 1000) %>% 
  step_tfidf(all_predictors())
embeddings_rec <- recipe(y~., data = train_data) %>% 
  step_tokenize(text) %>% 
  step_stem(text) %>% 
  step_stopwords(text) %>% 
  step_tokenfilter(text, max_tokens = 1000) %>% 
  step_word_embeddings(text, embeddings = embedding_glove6b())
hash_rec <- recipe(y~., data = train_data) %>% 
  step_tokenize(text) %>% 
  step_stem(text) %>% 
  step_stopwords(text) %>% 
  step_tokenfilter(text, max_tokens = 1000) %>% 
  step_texthash(text, num_terms = 100) 
```


## Define models Term frequency

We define three models:

We set some of the parameters for tuning. 

### Logistic model

```{r}
#model_lg <- logistic_reg(mode = 'classification', penalty = tune(), mixture = 0.5) %>%
  #set_engine('glm', family = binomial) 
model_lg <- logistic_reg(mode = 'classification') %>%
  set_engine('glm', family = binomial)
```

### KNN model
```{r}
model_knn <- nearest_neighbor(neighbors = tune()) %>% 
  set_engine("kknn") %>% 
  set_mode("classification")
```


### Random Forrest
```{r}
model_rf <- 
  rand_forest(trees = NULL, mtry = NULL, min_n = NULL) %>% 
  set_engine("ranger", importance = "impurity") %>% 
  set_mode("classification")
```


### Decision tree
```{r}
model_dt <- decision_tree(mode = 'classification',
                          cost_complexity = tune(),
                          tree_depth = tune(), 
                          min_n = tune()
                          ) %>%
  set_engine('rpart') 
```

## Workflow 

We create workflows for each recipe. 

### tf_idf

```{r}
workflow_general_tf <- workflow() %>%
  add_recipe(tf_idf_rec)
workflow_lg_tf <- workflow_general_tf %>%
  add_model(model_lg)
workflow_knn_tf <- workflow_general_tf %>%
  add_model(model_knn)
workflow_rf_tf <- workflow_general_tf %>%
  add_model(model_rf)
workflow_dt_tf <- workflow_general_tf %>%
  add_model(model_dt)
```


### Embeding

```{r}
workflow_general_emb <- workflow() %>%
  add_recipe(embeddings_rec)
workflow_lg_emb <- workflow_general_emb %>%
  add_model(model_lg)
workflow_knn_emb <- workflow_general_emb %>%
  add_model(model_knn)
workflow_rf_emb <- workflow_general_emb %>%
  add_model(model_rf)
workflow_dt_emb <- workflow_general_emb %>%
  add_model(model_dt)
```


### hash

```{r}
workflow_general_hash <- workflow() %>%
  add_recipe(hash_rec)
workflow_lg_hash <- workflow_general_hash %>%
  add_model(model_lg)
workflow_knn_hash <- workflow_general_hash %>%
  add_model(model_knn)
workflow_rf_hash <- workflow_general_hash %>%
  add_model(model_rf)
workflow_dt_hash <- workflow_general_hash %>%
  add_model(model_dt)
```

## Hyper tuneing 

We use vfold_cv to create resampled data. to perfrom hypertuning and fitting. 
```{r}
set.seed(100)
k_folds_data <- train_data %>% 
  vfold_cv(strata = y,
           v = 3,
           repeats = 3)
```

### Define Grids

We define the grids we want to use for the hypertuning 
```{r}
#logistic_grid <- grid_regular(parameters(model_lg), levels = 3)
logistic_grid <- 5
# knn_grid <- grid_regular(parameters(model_knn), levels = 5, filter = c(neighbors > 1))
knn_grid <- 5
dt_grid <- 5
rf_grid <- 5
```
The level defines the amount of parameters that should be considered. 

### Define tuning process

We define which measures we want to be able to choose best parameters from. 
```{r}
model_control <- control_grid(save_pred = TRUE)
model_metrics <- metric_set(accuracy, sens, spec, mn_log_loss, roc_auc)
```


### Tune Models

We tune the three different models 
```{r}
library(text2vec)
# Tune hash models
linear_hash_res <- tune_grid(
  model_lg,
  hash_rec,
  grid = logistic_grid,
  control = model_control,
  metrics = model_metrics,
  resamples = k_folds_data
)
knn_hash_res <- tune_grid(
  model_knn,
  hash_rec,
  grid = knn_grid,
  control = model_control,
  metrics = model_metrics,
  resamples = k_folds_data
)

#rf_hash_res <- tune_grid(
  #model_rf,
  #hash_rec,
  #grid = rf_grid,
  #control = model_control,
  #metrics = model_metrics,
  #resamples = k_folds_data
#)

dt_hash_res <- tune_grid(
  model_dt,
  hash_rec,
  grid = dt_grid,
  control = model_control,
  metrics = model_metrics,
  resamples = k_folds_data
)
```


```{r}
# Tune embed models
linear_embed_res <- tune_grid(
  model_lg,
  embeddings_rec,
  grid = logistic_grid,
  control = model_control,
  metrics = model_metrics,
  resamples = k_folds_data
)
knn_embed_res <- tune_grid(
  model_knn,
  embeddings_rec,
  grid = knn_grid,
  control = model_control,
  metrics = model_metrics,
  resamples = k_folds_data
)
#rf_embed_res <- tune_grid(
  #model_rf,
  #embeddings_rec,
  #grid = rf_grid,
  #control = model_control,
  #metrics = model_metrics,
  #resamples = k_folds_data
#)
dt_embed_res <- tune_grid(
  model_dt,
  embeddings_rec,
  grid = dt_grid,
  control = model_control,
  metrics = model_metrics,
  resamples = k_folds_data
)
```


```{r}
# Tune tf-idf models
linear_tf_res <- tune_grid(
  model_lg,
  tf_idf_rec,
  grid = logistic_grid,
  control = model_control,
  metrics = model_metrics,
  resamples = k_folds_data
)
knn_tf_res <- tune_grid(
  model_knn,
  tf_idf_rec,
  grid = knn_grid,
  control = model_control,
  metrics = model_metrics,
  resamples = k_folds_data
)
#rf_tf_res <- tune_grid(
  #model_rf,
  #tf_idf_rec,
  #grid = rf_grid,
  #control = model_control,
  #metrics = model_metrics,
  #resamples = k_folds_data
#)
dt_tf_res <- tune_grid(
  model_dt,
  tf_idf_rec,
  grid = dt_grid,
  control = model_control,
  metrics = model_metrics,
  resamples = k_folds_data
)
```


### Best parameters

We look at the different optimizations and choose the best parameters. 

#### linear_embed_res

Denne virker ikke, da hypertuning ikke virker til log reg
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
linear_hash_res %>% autoplot()
```

```{r}
best_param_linear_hash_res <- linear_hash_res %>% select_best(metric = 'accuracy')
best_param_linear_hash_res
```


#### knn_embed_res

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
knn_hash_res %>% autoplot()
```

```{r}
best_param_knn_hash_res <- knn_hash_res %>% select_best(metric = 'accuracy')
best_param_knn_hash_res
```

#### random forest hash
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
rf_hash_res %>% autoplot()
```

```{r}
best_param_rf_hash_res <- rf_hash_res %>% select_best(metric = 'accuracy')
best_param_rf_hash_res
```

#### decision tree hash
```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
dt_hash_res %>% autoplot()
```

```{r}
best_param_dt_hash_res <- dt_hash_res %>% select_best(metric = 'accuracy')
best_param_dt_hash_res
```


#### linear_embed_res

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
linear_embed_res %>% autoplot()
```

```{r}
best_param_linear_embed_res <- linear_embed_res %>% select_best(metric = 'accuracy')
best_param_linear_embed_res
```
#### knn_embed_res

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
knn_embed_res %>% autoplot()
```

```{r}
best_param_knn_embed_res <- knn_embed_res %>% select_best(metric = 'accuracy')
best_param_knn_embed_res
```

#### rf_embed_res

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
rf_embed_res %>% autoplot()
```

```{r}
best_param_rf_embed_res <- rf_embed_res %>% select_best(metric = 'accuracy')
best_param_rf_embed_res
```

#### dt_embed_res

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
dt_embed_res %>% autoplot()
```

```{r}
best_param_dt_embed_res <- dt_embed_res %>% select_best(metric = 'accuracy')
best_param_dt_embed_res
```

#### linear_tf_res

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
linear_tf_res %>% autoplot()
```

```{r}
best_param_linear_tf_res <- linear_tf_res %>% select_best(metric = 'accuracy')
best_param_linear_tf_res
```

#### knn_tf_res

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
knn_tf_res %>% autoplot()
```

```{r}
best_param_knn_tf_res <- knn_tf_res %>% select_best(metric = 'accuracy')
best_param_knn_tf_res
```

#### rf_tf_res

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
rf_tf_res %>% autoplot()
```

```{r}
best_param_rf_tf_res <- rf_tf_res %>% select_best(metric = 'accuracy')
best_param_rf_tf_res
```

#### dt_tf_res

```{r, tidy=TRUE, tidy.opts=list(width.cutoff=60)}
dt_tf_res %>% autoplot()
```

```{r}
best_param_dt_tf_res <- dt_tf_res %>% select_best(metric = 'accuracy')
best_param_dt_tf_res
```


## Finalize workflows

We now fit the best parameters into the workflow of the two models that needed hypertuning. 

### Hash

```{r}
workflow_final_lg_hash <- workflow_lg_hash %>%
  finalize_workflow(parameters = best_param_linear_hash_res)
workflow_final_knn_hash <- workflow_knn_hash %>%
  finalize_workflow(parameters = best_param_knn_hash_res)
#workflow_final_rf_hash <- workflow_rf_hash %>%
 # finalize_workflow(parameters = best_param_rf_hash_res)
workflow_final_dt_hash <- workflow_dt_hash %>%
  finalize_workflow(parameters = best_param_dt_hash_res)
```


### Tf-idf

```{r}
workflow_final_lg_tf <- workflow_lg_tf %>%
  finalize_workflow(parameters = best_param_linear_tf_res)
workflow_final_knn_tf <- workflow_knn_tf %>%
  finalize_workflow(parameters = best_param_knn_tf_res)
#workflow_final_rf_tf <- workflow_rf_tf %>%
 # finalize_workflow(parameters = best_param_rf_tf_res)
workflow_final_dt_tf <- workflow_dt_tf %>%
  finalize_workflow(parameters = best_param_dt_tf_res)
```


### Embedings

```{r}
workflow_final_lg_emb <- workflow_lg_emb %>%
  finalize_workflow(parameters = best_param_linear_embed_res)
workflow_final_knn_emb <- workflow_knn_emb %>%
  finalize_workflow(parameters = best_param_knn_embed_res)
#workflow_final_rf_emb <- workflow_rf_emb %>%
 # finalize_workflow(parameters = best_param_rf_embed_res)
workflow_final_dt_emb <- workflow_dt_emb %>%
  finalize_workflow(parameters = best_param_dt_embed_res)
```


## Evaluate models


here we us the resampled data to evaluate the models. 

### Logistic regression


#### hash

```{r}
log_res_hash <- 
  workflow_final_lg_hash %>% 
  fit_resamples(
    resamples = k_folds_data, 
    metrics = metric_set(
      recall, precision, f_meas, 
      accuracy, kap,
      roc_auc, sens, spec),
    control = control_resamples(
      save_pred = TRUE)
    ) 
log_res_hash %>% collect_metrics(summarize = TRUE)
```

#### Tf_idf

```{r}
log_res_tf <- 
  workflow_final_lg_tf %>% 
  fit_resamples(
    resamples = k_folds_data, 
    metrics = metric_set(
      recall, precision, f_meas, 
      accuracy, kap,
      roc_auc, sens, spec),
    control = control_resamples(
      save_pred = TRUE)
    ) 
log_res_tf %>% collect_metrics(summarize = TRUE)
```
#### Embeding

```{r}
log_res_emb <- 
  workflow_final_lg_emb %>% 
  fit_resamples(
    resamples = k_folds_data, 
    metrics = metric_set(
      recall, precision, f_meas, 
      accuracy, kap,
      roc_auc, sens, spec),
    control = control_resamples(
      save_pred = TRUE)
    ) 
log_res_emb %>% collect_metrics(summarize = TRUE)
```



### KNN model

#### Hash

```{r}
knn_res_hash <- 
  workflow_final_knn_hash %>% 
  fit_resamples(
    resamples = k_folds_data, 
    metrics = metric_set(
      recall, precision, f_meas, 
      accuracy, kap,
      roc_auc, sens, spec),
    control = control_resamples(
      save_pred = TRUE)
    ) 
knn_res_hash %>% collect_metrics(summarize = TRUE)
```

#### TF-idf

```{r}
knn_res_tf <- 
  workflow_final_knn_tf %>% 
  fit_resamples(
    resamples = k_folds_data, 
    metrics = metric_set(
      recall, precision, f_meas, 
      accuracy, kap,
      roc_auc, sens, spec),
    control = control_resamples(
      save_pred = TRUE)
    ) 
knn_res_tf %>% collect_metrics(summarize = TRUE)
```

#### Embedings

```{r}
knn_res_emb <- 
  workflow_final_knn_emb %>% 
  fit_resamples(
    resamples = k_folds_data, 
    metrics = metric_set(
      recall, precision, f_meas, 
      accuracy, kap,
      roc_auc, sens, spec),
    control = control_resamples(
      save_pred = TRUE)
    ) 
knn_res_emb %>% collect_metrics(summarize = TRUE)
```

### Random forest model

#### hash

```{r}
rf_res_hash <- 
  workflow_rf_hash %>% 
  fit_resamples(
    resamples = k_folds_data, 
    metrics = metric_set(
      recall, precision, f_meas, 
      accuracy, kap,
      roc_auc, sens, spec),
    control = control_resamples(
      save_pred = TRUE)
    ) 
rf_res_hash %>% collect_metrics(summarize = TRUE)
```

#### TF-idf

```{r}
rf_res_tf <- 
  workflow_rf_tf %>% 
  fit_resamples(
    resamples = k_folds_data, 
    metrics = metric_set(
      recall, precision, f_meas, 
      accuracy, kap,
      roc_auc, sens, spec),
    control = control_resamples(
      save_pred = TRUE)
    ) 
rf_res_tf %>% collect_metrics(summarize = TRUE)
```

#### Embedings

```{r}
rf_res_emb <- 
  workflow_rf_emb %>% 
  fit_resamples(
    resamples = k_folds_data, 
    metrics = metric_set(
      recall, precision, f_meas, 
      accuracy, kap,
      roc_auc, sens, spec),
    control = control_resamples(
      save_pred = TRUE)
    ) 
rf_res_emb %>% collect_metrics(summarize = TRUE)
```
### Decision tree


#### hash

```{r}
dt_res_hash <- 
  workflow_final_dt_hash %>% 
  fit_resamples(
    resamples = k_folds_data, 
    metrics = metric_set(
      recall, precision, f_meas, 
      accuracy, kap,
      roc_auc, sens, spec),
    control = control_resamples(
      save_pred = TRUE)
    ) 
dt_res_hash %>% collect_metrics(summarize = TRUE)
```

#### Tf_idf

```{r}
dt_res_tf <- 
  workflow_final_dt_tf %>% 
  fit_resamples(
    resamples = k_folds_data, 
    metrics = metric_set(
      recall, precision, f_meas, 
      accuracy, kap,
      roc_auc, sens, spec),
    control = control_resamples(
      save_pred = TRUE)
    ) 
dt_res_tf %>% collect_metrics(summarize = TRUE)
```
#### Embeding

```{r}
dt_res_emb <- 
  workflow_final_dt_emb %>% 
  fit_resamples(
    resamples = k_folds_data, 
    metrics = metric_set(
      recall, precision, f_meas, 
      accuracy, kap,
      roc_auc, sens, spec),
    control = control_resamples(
      save_pred = TRUE)
    ) 
dt_res_emb %>% collect_metrics(summarize = TRUE)
```

## Compare performance

We get a summary for the performed models. We add the model name to each metric to keep the models appart from each other later on. 

```{r}
log_metrics_tf <- 
  log_res_tf %>% 
  collect_metrics(summarise = TRUE) %>%
  mutate(model = "Logistic Regression TF-idf") 
log_metrics_emb <- 
  log_res_emb %>% 
  collect_metrics(summarise = TRUE) %>%
  mutate(model = "Logistic Regression Embeding") 
log_metrics_hash <- 
  log_res_hash %>% 
  collect_metrics(summarise = TRUE) %>%
  mutate(model = "Logistic Regression Hash") 
rf_metrics_tf <- 
  rf_res_tf %>% 
  collect_metrics(summarise = TRUE) %>%
  mutate(model = "Random Forest TF-idf")
rf_metrics_emb <- 
  rf_res_emb %>% 
  collect_metrics(summarise = TRUE) %>%
  mutate(model = "Random Forest Embeding")
rf_metrics_hash <- 
  rf_res_hash %>% 
  collect_metrics(summarise = TRUE) %>%
  mutate(model = "Random Forest Hash")
knn_metrics_tf <- 
  knn_res_tf %>% 
  collect_metrics(summarise = TRUE) %>%
  mutate(model = "Knn TF-idf")
knn_metrics_emb <- 
  knn_res_emb %>% 
  collect_metrics(summarise = TRUE) %>%
  mutate(model = "Knn Embeding")
knn_metrics_hash <- 
  knn_res_hash %>% 
  collect_metrics(summarise = TRUE) %>%
  mutate(model = "Knn Hash")
dt_metrics_tf <- 
  dt_res_tf %>% 
  collect_metrics(summarise = TRUE) %>%
  mutate(model = "DT TF-idf")
dt_metrics_emb <- 
  dt_res_emb %>% 
  collect_metrics(summarise = TRUE) %>%
  mutate(model = "DT Embeding")
dt_metrics_hash <- 
  dt_res_hash %>% 
  collect_metrics(summarise = TRUE) %>%
  mutate(model = "DT Hash")
```

```{r}
model_compare <- bind_rows(
                          log_metrics_tf,
                          log_metrics_emb,
                          log_metrics_hash,
                          rf_metrics_tf,
                          rf_metrics_emb,
                          rf_metrics_hash,
                          knn_metrics_tf,
                          knn_metrics_emb,
                          knn_metrics_hash,
                          dt_metrics_tf,
                          dt_metrics_emb,
                          dt_metrics_hash
                           ) 
model_comp <- 
  model_compare %>% 
  select(model, .metric, mean, std_err) %>% 
  pivot_wider(names_from = .metric, values_from = c(mean, std_err)) 
library(RColorBrewer)
nb.cols <- 12
mycolors <- colorRampPalette(brewer.pal(8, "Set2"))(nb.cols)
model_comp %>% 
  arrange(mean_f_meas) %>% 
  mutate(model = fct_reorder(model, mean_f_meas)) %>% 
  ggplot(aes(model, mean_f_meas, fill=model)) +
  geom_col() +
  coord_flip() +
  scale_fill_manual(values = mycolors) +
  #scale_fill_brewer(palette = "Blues") +
   geom_text(
     size = 3,
     aes(label = round(mean_f_meas, 2), y = mean_f_meas + 0.08),
     vjust = 1
  )
```

```{r}
model_comp %>% 
  arrange(mean_roc_auc) %>% 
  mutate(model = fct_reorder(model, mean_roc_auc)) %>%
  ggplot(aes(model, mean_roc_auc, fill=model)) +
  geom_col() +
  coord_flip() +
  scale_fill_manual(values = mycolors) +
  #scale_fill_brewer(palette = "Blues") + 
     geom_text(
     size = 3,
     aes(label = round(mean_roc_auc, 2), y = mean_roc_auc + 0.08),
     vjust = 1
  )
```

## Choose model

The best model seems to be Random Forest using TF-idf we also look at the second best model which is random forest using hash.

So we only continue with the two best ones. 


### Random forest model with TF IDF

#### Performance metrics
Show average performance over all folds: 

```{r}
rf_res_tf %>%  collect_metrics(summarize = TRUE)
```
#### Collect model predictions
To obtain the actual model predictions, we use the function collect_predictions and save the result as rf_pred_tf:

```{r}
rf_pred_tf <- 
  rf_res_tf %>%
  collect_predictions()
```

#### Confusion Matrix

We can now use our collected predictions to make a confusion matrix
```{r}
rf_pred_tf %>% 
  conf_mat(y, .pred_class) 
```

```{r}
rf_pred_tf %>% 
  conf_mat(y, .pred_class) %>% 
  autoplot(type = "heatmap")
```
We can see the model does okay predicting the correct classes. 

#### ROC curve

We will now create the ROC curve with 1 - specificity on the x-axis (false positive fraction = FP/(FP+TN)) and sensitivity on the y axis (true positive fraction = TP/(TP+FN)). 
```{r}
rf_pred_tf %>% 
  roc_curve(y,.pred_0) %>% 
  autoplot()
```



### Random forest model hash

#### Collect model predictions
To obtain the actual model predictions, we use the function collect_predictions and save the result as rf_pred_hash:

```{r}
rf_pred_hash <- 
  rf_res_hash %>%
  collect_predictions()
```

#### Performance metrics
Show average performance over all folds (note that we use rf_res):

```{r}
rf_res_hash %>%  collect_metrics(summarize = TRUE)
```


#### Confusion Matrix

We can now use our collected predictions to make a confusion matrix
```{r}
rf_pred_hash %>% 
  conf_mat(y, .pred_class) 
```


```{r}
rf_pred_hash %>% 
  conf_mat(y, .pred_class) %>% 
  autoplot(type = "heatmap")
```


#### ROC curve

We will now create the ROC curve with 1 - specificity on the x-axis (false positive fraction = FP/(FP+TN)) and sensitivity on the y axis (true positive fraction = TP/(TP+FN)). 
```{r}
rf_pred_hash %>% 
  roc_curve(y, .pred_0) %>% 
  autoplot()
```

## Models on test data

We now want to look at how the two models perform on test data. 

### Random forest model TF IDF

```{r}
last_fit_rf <- last_fit(workflow_rf_tf, 
                        split = tidy_split,
                        metrics = metric_set(
                          recall, precision, f_meas, 
                          accuracy, kap,
                          roc_auc, sens, spec)
                        )
```


```{r}
last_fit_rf %>% 
  collect_metrics()
```

We can again make a confusion matrix on the test data predictions

```{r}
last_fit_rf %>%
  collect_predictions() %>% 
  conf_mat(y, .pred_class) %>% 
  autoplot(type = "heatmap")
```

```{r}
last_fit_rf %>% 
  collect_predictions() %>% 
  roc_curve(y, .pred_0) %>% 
  autoplot()
```

### Random forest hash

```{r}
last_fit_rf_hash <- last_fit(workflow_rf_hash, 
                        split = tidy_split,
                        metrics = metric_set(
                          recall, precision, f_meas, 
                          accuracy, kap,
                          roc_auc, sens, spec)
                        )
```


```{r}
last_fit_rf_hash %>% 
  collect_metrics()
```

```{r}
last_fit_rf_hash %>%
  collect_predictions() %>% 
  conf_mat(y, .pred_class) %>% 
  autoplot(type = "heatmap")
```

```{r}
last_fit_rf_hash %>% 
  collect_predictions() %>% 
  roc_curve(y, .pred_0) %>% 
  autoplot()
```
